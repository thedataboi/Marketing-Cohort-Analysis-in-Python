{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Cohort Analysis in Python\n",
    "\n",
    "In this tutorial well we looking at how to create a a cohort analysis from scratch in Python using the Pandas library and pivot table. This tutorial was originally created by <a href=\"https://medium.com/@henryfeng/know-users-behaviors-better-with-cohort-analysis-in-python-6c0dfc373963\">Henry Feng</a> of amazon.\n",
    "\n",
    "I've added some new aspects, update the code and adapted the tutorial for those that my not have previous experince in Python to make it easier to understand what's happening in each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # calculation\n",
    "import pandas as pd # Excel for Python\n",
    "import datetime as dt # allow for date and time series manipulation\n",
    "import seaborn as sns # a charting package\n",
    "import matplotlib.pyplot as plt # the original Python chating package\n",
    "\n",
    "#a `magic code` that allows ploting of charts within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Sets all rows to display\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Stops a false alarm chaining error\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Let me introduce an important part of Python. Reusable code. Resuable code in this case comes as a 'helper' function. These are little bespoke functions we build to handle reptitive tasks.\n",
    "\n",
    "The function below aggrates the statstical and descriptive data about the data set we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(x):\n",
    "    divider = \"*_*\"\n",
    "    print(\"\\n {} \\n\".format((divider*20))) #creates a dvider between each method output breaking at each end.\n",
    "    \n",
    "    print(\"Dataframe Makeup \\n\") #title for output.\n",
    "    \n",
    "    x.info() # Explains what the data and values the data is madeup from.\n",
    "    \n",
    "    print(\"\\n {} \\n\".format((divider*20))) #creates a dvider between each method output breaking at each end.\n",
    "    \n",
    "    print(\"Descriptive Statistics \\n\\n\", x.describe().round(2)) #Gives a statstical breakdown of the data.\n",
    "    \n",
    "    print(\"\\n {} \\n\".format((divider*20))) #creates a dvider between each method output breaking at each end.\n",
    "    \n",
    "    print(\"Shape of dataframe: {}\".format(x.shape)) # Gives the shape of the data.\n",
    "    \n",
    "    print(\"\\n {} \\n\".format((divider*20))) #creates a dvider between each method output breaking at each end.\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "In order to use data in Python you need to be explicit. What that means is remove or replace data which isn't valid. In many cases this also means transforming data but we will not cover this in this tutorial.\n",
    "\n",
    "In this section we want to clean up the data so that there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that sums all of the missing data from each row so that we can count what we have\n",
    "\n",
    "def missing_data(x):\n",
    "    return x.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops missing data from the CustomerID column\n",
    "cleaned_data = data.dropna(subset=['CustomerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.head() #view the top 5 rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Munging and Wrangling data\n",
    "\n",
    "Whenever using Python you will always need to munge or wrangle the data. These are fun sound words for formating and processing data. Unlike software such as Excel or GSheets Pandas doesn't try to guess formats. You need to be explicit in the formating of each column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the datetime function to gets the month a datetime stamp and strips the time\n",
    "def get_month(x):\n",
    "    return dt.datetime(x.year, x.month, 1) #year, month, incremints of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column \n",
    "cleaned_data['InvoiceMonth'] = cleaned_data['InvoiceDate'].apply(get_month) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always inspect the data you've just created\n",
    "cleaned_data['InvoiceMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a CohortMonth column by grouping data and selecting the earliest instance in the data. \n",
    "cleaned_data['CohortMonth'] = cleaned_data.groupby('CustomerID')['InvoiceMonth'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['CohortMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Cohort\n",
    "So far we've been doing the admin. Inspecting and cleaning up the data is a key part in any data anlysis with Python. Now we will create a cohort which to analyise and visualise...but first, you guessed it, more data processing.\n",
    "\n",
    "Here we are going to create the cohort index. This will give the month lapsed number first and last transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When passed a datetime column this functions splits out year, month, day\n",
    "\n",
    "def get_date(df, column):\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits invoiced month and data into single variables\n",
    "invoice_year, invoice_month, _ = get_date(cleaned_data, 'InvoiceMonth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Inspect the variable\n",
    "invoice_month[:30] #[:30] selects the first 30 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Inspect the variable\n",
    "invoice_year[:30] #[:30] selects the first 30 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits cohort month and data into single variables\n",
    "cohort_year, cohort_month, _ = get_date(cleaned_data, 'CohortMonth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cohort_month[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cohort_year[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a variable which holds the differnce between the invoice and cohort year \n",
    "year_diff = invoice_year - cohort_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a variable which holds the differnce between the invoice and cohort month \n",
    "month_diff = invoice_month - cohort_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now creating a column that has the calclation shows the \n",
    "cleaned_data['CohortIndex'] = year_diff * 12 + month_diff + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['CohortIndex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Analysis 1\n",
    "\n",
    "Finally we create a Cohort Analysis. We're using, what I deem to be, the top most used function for marketering doing data analysis <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\">`pd.groupby()`</a>. This allows you to group data by a specific column. Then we'll be using <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html\">`pd. pivot_table()`</a> to convert the data into a what you would typically recognise as a Cohort Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the data by columns CohortMonth','CohortIndex' then aggreate by column 'CustomerID'\n",
    "cohort_data = cleaned_data.groupby(\n",
    "    ['CohortMonth', 'CohortIndex'])['CustomerID'].apply(pd.Series.nunique).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the cohort_data and plumb it into a Pivot Table. Setting index, columns and values as below.\n",
    "cohort_count = cohort_data.pivot_table(index = 'CohortMonth',\n",
    "                                       columns = 'CohortIndex',\n",
    "                                       values = 'CustomerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create retention as a percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_size = cohort_count.iloc[:,0] #select all the rows : select the first column\n",
    "retention = cohort_count.divide(cohort_size, axis=0) #Divide the cohort by the first column\n",
    "retention.round(3) # round the retention to 3 places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating cohort heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (11,9))\n",
    "plt.title('Cohort Analysis - Retention Rate')\n",
    "sns.heatmap(data = retention, \n",
    "            annot = True, \n",
    "            fmt = '.0%', \n",
    "            vmin = 0.0,\n",
    "            vmax = 0.5,\n",
    "            cmap = \"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Quantity Sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cohort_data2 = cleaned_data.groupby(['CohortMonth', 'CohortIndex'])['Quantity'].mean().reset_index()\n",
    "average_quantity  = cohort_data2.pivot_table(index = 'CohortMonth',\n",
    "                                            columns = 'CohortIndex',\n",
    "                                       values = 'Quantity').round(1)\n",
    "average_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (11,9))\n",
    "plt.title('Cohort Analysis - Average Quantity')\n",
    "sns.heatmap(data = average_quantity, \n",
    "            annot = True, \n",
    "            cmap = \"BuGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column for Total Sales \n",
    "cleaned_data['TotalSale'] = cleaned_data['Quantity'] * cleaned_data['UnitPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['TotalSale'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_data3 = cleaned_data.groupby(['CohortMonth', 'CohortIndex'])['TotalSale'].mean().reset_index()\n",
    "average_sales  = cohort_data3.pivot_table(index = 'CohortMonth',\n",
    "                                           columns = 'CohortIndex',\n",
    "                                      values = 'TotalSale').round(1)\n",
    "average_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (11,9))\n",
    "plt.title('Cohort Analysis - Average Sales')\n",
    "sns.heatmap(data = average_sales, \n",
    "            annot = True, \n",
    "            cmap = \"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
